{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ab8f0dc",
   "metadata": {},
   "source": [
    "## How I Accidentally Built an AI SQL Assistant at Work\n",
    "\n",
    "A Python dev‚Äôs story of building an internal AI chatbot that turns natural language into SQL ‚Äî no deep learning expertise required.\n",
    "\n",
    "### Step 1: Don‚Äôt Build an Assistant. Just Answer One Question.\n",
    "The phrase ‚ÄúAI Assistant‚Äù sounds intimidating. \n",
    "\n",
    "Break it down. What the team really wanted was to ask questions like:\n",
    "\n",
    "‚ÄúList all employees who joined last year‚Äù\n",
    "‚ÄúShow me average salary by department‚Äù\n",
    "‚Ä¶and get a usable SQL query in return. That‚Äôs it.\n",
    "\n",
    "Take a sentence in plain English ‚Üí return a working SQL query.\n",
    "\n",
    "No chatbot. No user accounts. Just a Flask app with a box to type in and a box to show output.\n",
    "\n",
    "### Step 2: Pick a Model That Actually Knows SQL\n",
    "There are hundreds of large language models out there, but most are trained on general text. \n",
    "\n",
    "- OpenAI‚Äôs GPT-3.5: surprisingly good, but $$$ and privacy concerns.\n",
    "- T5 fine-tuned on WikiSQL: decent for basics, broke easily on custom schemas.\n",
    "- Defog‚Äôs sqlcoder-7b-2 (üí° my winner): open-source, SQL-native, and surprisingly good with schema-aware prompting.\n",
    "And here‚Äôs the best part ‚Äî you can run it locally using 4-bit quantization with BitsAndBytes, so you don‚Äôt need a $10k GPU setup.\n",
    "\n",
    "### Step 3: Build a Tiny Flask App to Run Local Inference\n",
    "I didn‚Äôt need anything fancy. I just wanted a simple playground. Here‚Äôs a mini version of the app‚Äôs core logic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9c7a4d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bitsandbytes in /Users/ulrike_imac_air/projects/code/code_env/lib/python3.13/site-packages (0.42.0)\n",
      "Requirement already satisfied: scipy in /Users/ulrike_imac_air/projects/code/code_env/lib/python3.13/site-packages (from bitsandbytes) (1.15.2)\n",
      "Requirement already satisfied: numpy<2.5,>=1.23.5 in /Users/ulrike_imac_air/projects/code/code_env/lib/python3.13/site-packages (from scipy->bitsandbytes) (2.2.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: accelerate in /Users/ulrike_imac_air/projects/code/code_env/lib/python3.13/site-packages (1.6.0)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /Users/ulrike_imac_air/projects/code/code_env/lib/python3.13/site-packages (from accelerate) (2.2.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/ulrike_imac_air/projects/code/code_env/lib/python3.13/site-packages (from accelerate) (24.2)\n",
      "Requirement already satisfied: psutil in /Users/ulrike_imac_air/projects/code/code_env/lib/python3.13/site-packages (from accelerate) (7.0.0)\n",
      "Requirement already satisfied: pyyaml in /Users/ulrike_imac_air/projects/code/code_env/lib/python3.13/site-packages (from accelerate) (6.0.2)\n",
      "Requirement already satisfied: torch>=2.0.0 in /Users/ulrike_imac_air/projects/code/code_env/lib/python3.13/site-packages (from accelerate) (2.7.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /Users/ulrike_imac_air/projects/code/code_env/lib/python3.13/site-packages (from accelerate) (0.30.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/ulrike_imac_air/projects/code/code_env/lib/python3.13/site-packages (from accelerate) (0.5.3)\n",
      "Requirement already satisfied: filelock in /Users/ulrike_imac_air/projects/code/code_env/lib/python3.13/site-packages (from huggingface-hub>=0.21.0->accelerate) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/ulrike_imac_air/projects/code/code_env/lib/python3.13/site-packages (from huggingface-hub>=0.21.0->accelerate) (2025.3.2)\n",
      "Requirement already satisfied: requests in /Users/ulrike_imac_air/projects/code/code_env/lib/python3.13/site-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Users/ulrike_imac_air/projects/code/code_env/lib/python3.13/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/ulrike_imac_air/projects/code/code_env/lib/python3.13/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.13.2)\n",
      "Requirement already satisfied: setuptools in /Users/ulrike_imac_air/projects/code/code_env/lib/python3.13/site-packages (from torch>=2.0.0->accelerate) (80.3.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/ulrike_imac_air/projects/code/code_env/lib/python3.13/site-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
      "Requirement already satisfied: networkx in /Users/ulrike_imac_air/projects/code/code_env/lib/python3.13/site-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Users/ulrike_imac_air/projects/code/code_env/lib/python3.13/site-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/ulrike_imac_air/projects/code/code_env/lib/python3.13/site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/ulrike_imac_air/projects/code/code_env/lib/python3.13/site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/ulrike_imac_air/projects/code/code_env/lib/python3.13/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/ulrike_imac_air/projects/code/code_env/lib/python3.13/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/ulrike_imac_air/projects/code/code_env/lib/python3.13/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/ulrike_imac_air/projects/code/code_env/lib/python3.13/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2025.4.26)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: transformers in /Users/ulrike_imac_air/projects/code/code_env/lib/python3.13/site-packages (4.51.3)\n",
      "Requirement already satisfied: filelock in /Users/ulrike_imac_air/projects/code/code_env/lib/python3.13/site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /Users/ulrike_imac_air/projects/code/code_env/lib/python3.13/site-packages (from transformers) (0.30.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/ulrike_imac_air/projects/code/code_env/lib/python3.13/site-packages (from transformers) (2.2.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/ulrike_imac_air/projects/code/code_env/lib/python3.13/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/ulrike_imac_air/projects/code/code_env/lib/python3.13/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/ulrike_imac_air/projects/code/code_env/lib/python3.13/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /Users/ulrike_imac_air/projects/code/code_env/lib/python3.13/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Users/ulrike_imac_air/projects/code/code_env/lib/python3.13/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/ulrike_imac_air/projects/code/code_env/lib/python3.13/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/ulrike_imac_air/projects/code/code_env/lib/python3.13/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/ulrike_imac_air/projects/code/code_env/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/ulrike_imac_air/projects/code/code_env/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/ulrike_imac_air/projects/code/code_env/lib/python3.13/site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/ulrike_imac_air/projects/code/code_env/lib/python3.13/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/ulrike_imac_air/projects/code/code_env/lib/python3.13/site-packages (from requests->transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/ulrike_imac_air/projects/code/code_env/lib/python3.13/site-packages (from requests->transformers) (2025.4.26)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: torch in /Users/ulrike_imac_air/projects/code/code_env/lib/python3.13/site-packages (2.7.0)\n",
      "Requirement already satisfied: filelock in /Users/ulrike_imac_air/projects/code/code_env/lib/python3.13/site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Users/ulrike_imac_air/projects/code/code_env/lib/python3.13/site-packages (from torch) (4.13.2)\n",
      "Requirement already satisfied: setuptools in /Users/ulrike_imac_air/projects/code/code_env/lib/python3.13/site-packages (from torch) (80.3.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/ulrike_imac_air/projects/code/code_env/lib/python3.13/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in /Users/ulrike_imac_air/projects/code/code_env/lib/python3.13/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Users/ulrike_imac_air/projects/code/code_env/lib/python3.13/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /Users/ulrike_imac_air/projects/code/code_env/lib/python3.13/site-packages (from torch) (2025.3.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/ulrike_imac_air/projects/code/code_env/lib/python3.13/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/ulrike_imac_air/projects/code/code_env/lib/python3.13/site-packages (from jinja2->torch) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: flask in /Users/ulrike_imac_air/projects/code/code_env/lib/python3.13/site-packages (3.1.0)\n",
      "Requirement already satisfied: Werkzeug>=3.1 in /Users/ulrike_imac_air/projects/code/code_env/lib/python3.13/site-packages (from flask) (3.1.3)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in /Users/ulrike_imac_air/projects/code/code_env/lib/python3.13/site-packages (from flask) (3.1.6)\n",
      "Requirement already satisfied: itsdangerous>=2.2 in /Users/ulrike_imac_air/projects/code/code_env/lib/python3.13/site-packages (from flask) (2.2.0)\n",
      "Requirement already satisfied: click>=8.1.3 in /Users/ulrike_imac_air/projects/code/code_env/lib/python3.13/site-packages (from flask) (8.1.8)\n",
      "Requirement already satisfied: blinker>=1.9 in /Users/ulrike_imac_air/projects/code/code_env/lib/python3.13/site-packages (from flask) (1.9.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/ulrike_imac_air/projects/code/code_env/lib/python3.13/site-packages (from Jinja2>=3.1.2->flask) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Using `bitsandbytes` 4-bit quantization requires the latest version of bitsandbytes: `pip install -U bitsandbytes`",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     13\u001b[39m app = Flask(\u001b[34m__name__\u001b[39m)\n\u001b[32m     15\u001b[39m model_name = \u001b[33m\"\u001b[39m\u001b[33mdefog/sqlcoder-7b-2\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m model = \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mauto\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43mload_in_4bit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m     20\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m tokenizer = AutoTokenizer.from_pretrained(model_name)\n\u001b[32m     22\u001b[39m generator = pipeline(\u001b[33m\"\u001b[39m\u001b[33mtext-generation\u001b[39m\u001b[33m\"\u001b[39m, model=model, tokenizer=tokenizer)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/code/code_env/lib/python3.13/site-packages/transformers/models/auto/auto_factory.py:571\u001b[39m, in \u001b[36m_BaseAutoModelClass.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[39m\n\u001b[32m    569\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m model_class.config_class == config.sub_configs.get(\u001b[33m\"\u001b[39m\u001b[33mtext_config\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    570\u001b[39m         config = config.get_text_config()\n\u001b[32m--> \u001b[39m\u001b[32m571\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    572\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    573\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    574\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    575\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig.\u001b[34m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    576\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m.join(c.\u001b[34m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m._model_mapping.keys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    577\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/code/code_env/lib/python3.13/site-packages/transformers/modeling_utils.py:279\u001b[39m, in \u001b[36mrestore_default_torch_dtype.<locals>._wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    277\u001b[39m old_dtype = torch.get_default_dtype()\n\u001b[32m    278\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m279\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    280\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    281\u001b[39m     torch.set_default_dtype(old_dtype)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/code/code_env/lib/python3.13/site-packages/transformers/modeling_utils.py:4228\u001b[39m, in \u001b[36mPreTrainedModel.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[39m\n\u001b[32m   4225\u001b[39m     hf_quantizer = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   4227\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m hf_quantizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m4228\u001b[39m     \u001b[43mhf_quantizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate_environment\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4229\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4230\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfrom_tf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfrom_tf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4231\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfrom_flax\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfrom_flax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4232\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4233\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweights_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4234\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4235\u001b[39m     torch_dtype = hf_quantizer.update_torch_dtype(torch_dtype)\n\u001b[32m   4236\u001b[39m     device_map = hf_quantizer.update_device_map(device_map)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/code/code_env/lib/python3.13/site-packages/transformers/quantizers/quantizer_bnb_4bit.py:76\u001b[39m, in \u001b[36mBnb4BitHfQuantizer.validate_environment\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     72\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[32m     73\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUsing `bitsandbytes` 4-bit quantization requires Accelerate: `pip install \u001b[39m\u001b[33m'\u001b[39m\u001b[33maccelerate>=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mACCELERATE_MIN_VERSION\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m`\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     74\u001b[39m     )\n\u001b[32m     75\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_bitsandbytes_available():\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[32m     77\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mUsing `bitsandbytes` 4-bit quantization requires the latest version of bitsandbytes: `pip install -U bitsandbytes`\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     78\u001b[39m     )\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mintegrations\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m validate_bnb_backend_availability\n\u001b[32m     81\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m is_bitsandbytes_multi_backend_available\n",
      "\u001b[31mImportError\u001b[39m: Using `bitsandbytes` 4-bit quantization requires the latest version of bitsandbytes: `pip install -U bitsandbytes`"
     ]
    }
   ],
   "source": [
    "# %pip install flask transformers accelerate torch bitsandbytes\n",
    "%pip install -U bitsandbytes\n",
    "%pip install -U accelerate\n",
    "%pip install -U transformers\n",
    "%pip install -U torch\n",
    "%pip install -U flask\n",
    "# %pip install -U datasets\n",
    "# %pip install -U gradio\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "import torch\n",
    "from flask import Flask, request, jsonify\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "model_name = \"defog/sqlcoder-7b-2\"\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=\"auto\",\n",
    "    load_in_4bit=True\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "generator = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "@app.route(\"/generate\", methods=[\"POST\"])\n",
    "def generate_sql():\n",
    "    data = request.json\n",
    "    question = data[\"question\"]\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "You are a SQL expert. Use the following schema:\n",
    "\n",
    "Table: employees\n",
    "Columns: id, name, department, salary, date_joined\n",
    "\n",
    "### Convert the following question into a SQL query:\n",
    "{question}\n",
    "\n",
    "SQL:\n",
    "    \"\"\"\n",
    "    output = generator(prompt, max_new_tokens=150, do_sample=False)[0][\"generated_text\"]\n",
    "    return jsonify({\"sql\": output.split(\"SQL:\")[-1].strip()})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36fef81",
   "metadata": {},
   "source": [
    "Send a POST request with { \"question\": \"List employees in marketing\" }\n",
    "...and out comes a SQL query.\n",
    "\n",
    "### Step 4: Prompting Is the Hidden Superpower\n",
    "At first, I let users type questions and passed them directly to the model. The results were‚Ä¶ creative. The model hallucinated tables and columns like revenue_data_2022.\n",
    "\n",
    "Turns out, prompting matters a lot.\n",
    "\n",
    "By including a schema definition in the prompt every time, I gave the model enough grounding to stay accurate. Here‚Äôs my working template:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70c486e",
   "metadata": {},
   "outputs": [],
   "source": [
    "You are a SQL expert.\n",
    "Use the following schema:\n",
    "Table: employees\n",
    "Columns: id, name, department, salary, date_joined\n",
    "\n",
    "Convert the following question into a SQL query:\n",
    "[question goes here]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08633d5e",
   "metadata": {},
   "source": [
    "This one change improved results by about 70%.\n",
    "\n",
    "### Step 5: Make It Better (But Only When It Breaks)\n",
    "The coolest part? Once I shared the tool internally, other devs started using it ‚Äî and breaking it. That‚Äôs when the real learning happened.\n",
    "\n",
    "I added:\n",
    "\n",
    "A feedback button (‚ÄúWas this SQL correct?‚Äù)\n",
    "A log of all questions + generated queries\n",
    "A filter to remove unsafe queries (DROP, DELETE, etc.)\n",
    "I didn‚Äôt try to turn it into a polished product. I just made small improvements when the current version failed."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "code_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
